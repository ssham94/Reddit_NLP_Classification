{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement:  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Reading in Data:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer \n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in scraped data and dropping first column to set index\n",
    "df = pd.read_csv('./reddit_dataframe.csv')\n",
    "df.drop(columns = 'Unnamed: 0', inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ready to prove you're Challenger? /r/LeagueofL...</td>\n",
       "      <td>Hi Summoners,\\n\\nDrum roll please... we have s...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patch 9.7 Bug Megathread</td>\n",
       "      <td>Greetings Summoners!\\n\\nWith every new patch R...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the ability to remove all client animations.</td>\n",
       "      <td>Having to wait a duration longer than a Morgan...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know a champion is old when they still tal...</td>\n",
       "      <td>Udyr, Cho’gath and Mordekaiser are all pretty ...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbq Malice just locked in Tahm Kench jungle.</td>\n",
       "      <td>In the bbq OLIVERS vs APK PRINCE play-off seri...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles  \\\n",
       "0  Ready to prove you're Challenger? /r/LeagueofL...   \n",
       "1                           Patch 9.7 Bug Megathread   \n",
       "2   Add the ability to remove all client animations.   \n",
       "3  You know a champion is old when they still tal...   \n",
       "4       bbq Malice just locked in Tahm Kench jungle.   \n",
       "\n",
       "                                                Text        Subreddit  \n",
       "0  Hi Summoners,\\n\\nDrum roll please... we have s...  leagueoflegends  \n",
       "1  Greetings Summoners!\\n\\nWith every new patch R...  leagueoflegends  \n",
       "2  Having to wait a duration longer than a Morgan...  leagueoflegends  \n",
       "3  Udyr, Cho’gath and Mordekaiser are all pretty ...  leagueoflegends  \n",
       "4  In the bbq OLIVERS vs APK PRINCE play-off seri...  leagueoflegends  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that dataframe has been imported correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null values have already been dealt with during the web scraping section of code. No real data cleaning is necessary after dealing with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data had duplicates when first scraped from website. All duplicates will now be removed\n",
    "df.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ready to prove you're Challenger? /r/LeagueofL...</td>\n",
       "      <td>Hi Summoners,\\n\\nDrum roll please... we have s...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patch 9.7 Bug Megathread</td>\n",
       "      <td>Greetings Summoners!\\n\\nWith every new patch R...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the ability to remove all client animations.</td>\n",
       "      <td>Having to wait a duration longer than a Morgan...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know a champion is old when they still tal...</td>\n",
       "      <td>Udyr, Cho’gath and Mordekaiser are all pretty ...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbq Malice just locked in Tahm Kench jungle.</td>\n",
       "      <td>In the bbq OLIVERS vs APK PRINCE play-off seri...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles  \\\n",
       "0  Ready to prove you're Challenger? /r/LeagueofL...   \n",
       "1                           Patch 9.7 Bug Megathread   \n",
       "2   Add the ability to remove all client animations.   \n",
       "3  You know a champion is old when they still tal...   \n",
       "4       bbq Malice just locked in Tahm Kench jungle.   \n",
       "\n",
       "                                                Text        Subreddit  \n",
       "0  Hi Summoners,\\n\\nDrum roll please... we have s...  leagueoflegends  \n",
       "1  Greetings Summoners!\\n\\nWith every new patch R...  leagueoflegends  \n",
       "2  Having to wait a duration longer than a Morgan...  leagueoflegends  \n",
       "3  Udyr, Cho’gath and Mordekaiser are all pretty ...  leagueoflegends  \n",
       "4  In the bbq OLIVERS vs APK PRINCE play-off seri...  leagueoflegends  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renumbering indexes for easier manipulation and less confusion in future.\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = 'index', inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding title and text length to each post\n",
    "df['title_length'] = df['Titles'].map(lambda x: len(x))\n",
    "df['text_length'] = df['Text'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50.114490</td>\n",
       "      <td>666.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.651158</td>\n",
       "      <td>1783.406245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>137.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>298.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>606.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>29711.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_length   text_length\n",
       "count    559.000000    559.000000\n",
       "mean      50.114490    666.692308\n",
       "std       29.651158   1783.406245\n",
       "min        6.000000     11.000000\n",
       "25%       30.000000    137.500000\n",
       "50%       42.000000    298.000000\n",
       "75%       63.000000    606.000000\n",
       "max      195.000000  29711.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing stats for league of legends reddit posts\n",
    "mask = df['Subreddit'] == 'leagueoflegends'\n",
    "df[mask].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>494.000000</td>\n",
       "      <td>494.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46.309717</td>\n",
       "      <td>597.582996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.715337</td>\n",
       "      <td>1190.991935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>223.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>473.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.000000</td>\n",
       "      <td>9314.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_length  text_length\n",
       "count    494.000000   494.000000\n",
       "mean      46.309717   597.582996\n",
       "std       29.715337  1190.991935\n",
       "min        5.000000     9.000000\n",
       "25%       26.000000   110.000000\n",
       "50%       40.000000   223.500000\n",
       "75%       58.000000   473.250000\n",
       "max      260.000000  9314.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing stats for dota 2 subreddit posts\n",
    "mask = df['Subreddit'] == 'DotA2'\n",
    "df[mask].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to lemmatize texts and titles\n",
    "def lemmatize(text):\n",
    "    tokenizer = RegexpTokenizer(r'(\\$?(\\d+[\\.,]?)+%?|(\\/?\\w+)+)')\n",
    "    token = tokenizer.tokenize(text)\n",
    "    new_token = [i[0] for i in token]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_token = [lemmatizer.lemmatize(i) for i in new_token]\n",
    "    return (\" \".join(lem_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Summoners Drum roll please we have something really exciting to announce We ve partnered with Battlefy and ZOTAC to present the /r/LeagueofLegends Cup We ve been looking forward to organizing a subreddit tournament and now is your chance to prove you re the best and win some at the same time The tournament is for both EUW and NA with EUW being on Saturday 06 April and NA being on Sunday 07 April If there is enough interest we would like to open up more tournament This is going to be a 5 v5 Tournament Draft with some more detail below EUW What EUW Tournament 5 v5 Tournament Draft When 06 April 1 pm CEST Where Click here to sign up and for more info http /battlefy com/zotac cup/zotac cup present rleagueoflegends tournament europe/5c96c7a0bf44520328f43849/info infoTab rule NA What NA Tournament 5 v5 Tournament Draft When 07 April 12 pm PDT 3 PM EDT Where Click here to sign up and for more info http /battlefy com/zotac cup/zotac cup present rleagueoflegends tournament north america/5c96cbbcde5210034390a000/info infoTab detail Players must have a valid League of Legends account on the EU West or NA server in order to participate in this tournament Players must be 13 year of age or older to compete in this tournament Players must checkin to the tournament to complete the registration Checkin period start 60 minute prior to tournament start time and last 60 minute Players must checkin to each match within the allotted 10 min Tournament code will be available to create match lobby Tournament Settings Bracket Type Single Elimination Match Type Best of 1 Best of Three Finals Region/Server EU West/NA Team Format 5 v5 Tournament Draft Game Settings Game Type Tournament Draft Map Summoners Rift Pause Time Allowed 10 Minutes technical issue only No Show Time 10 Minutes The player in the upper side of the bracket or left side of the match page will play blue side The team in the lower side of the bracket or right side of the match page will play red side Core Rules All match will be played using the tournament code that Battlefy provides To get the code navigate to the bracket and then click on the match that you re supposed to play Then copy the code and paste it into the League of Legends game client by clicking play then selecting custom game then selecting the trophy icon Players will have only 10 minute to join the game room once it ha been created If your opponent doesn t show up or doesn t start the match in under these 10 minute please contact tournament admins in the Discord channel If a player suffers a disconnection the player will be given 10 minute to reconnect to the game the team with the disconnection can request for a pause If they have not reconnected in that time the team will have to continue playing without that player Players are allowed to stream their gameplay with at least a 3 minute delay at their own risk Play for a chance to win your share of $600 USD 1 st place team $300 2 nd place team $200 3 rd place team $100 Cash prize will be paid out within 10 business day via PayPal edit For those that are part of different server such a EUNE LAN Brazil Asia Servers KR CN Taiwan Singapore ZOTAC is also hosting a global tournament around the same time http /battlefy com/zotac cup fight for charity Sorry fam we didn t forget about you lt 3'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing that function works\n",
    "lemmatize(df['Text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating function to stem texts and titles\n",
    "def porterStemming(text):\n",
    "    tokenizer = RegexpTokenizer(r'(\\$?(\\d+[\\.,]?)+%?|(\\/?\\w+)+)')\n",
    "    token = tokenizer.tokenize(text)\n",
    "    new_token = [i[0] for i in token]\n",
    "    \n",
    "    p_stemmer = PorterStemmer()\n",
    "    port_token = [p_stemmer.stem(i) for i in new_token]\n",
    "    return (\" \".join(port_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi summon drum roll pleas we have someth realli excit to announc We ve partner with battlefi and zotac to present the /r/leagueoflegend cup We ve been look forward to organ a subreddit tournament and now is your chanc to prove you re the best and win some at the same time the tournament is for both euw and NA with euw be on saturday 06 april and NA be on sunday 07 april If there is enough interest we would like to open up more tournament thi is go to be a 5 v5 tournament draft with some more detail below euw what euw tournament 5 v5 tournament draft when 06 april 1 pm cest where click here to sign up and for more info http /battlefi com/zotac cup/zotac cup present rleagueoflegend tournament europe/5c96c7a0bf44520328f43849/info infotab rule NA what NA tournament 5 v5 tournament draft when 07 april 12 pm pdt 3 PM edt where click here to sign up and for more info http /battlefi com/zotac cup/zotac cup present rleagueoflegend tournament north america/5c96cbbcde5210034390a000/info infotab detail player must have a valid leagu of legend account on the EU west or NA server in order to particip in thi tournament player must be 13 year of age or older to compet in thi tournament player must checkin to the tournament to complet the registr checkin period start 60 minut prior to tournament start time and last 60 minut player must checkin to each match within the allot 10 min tournament code will be avail to creat match lobbi tournament set bracket type singl elimin match type best of 1 best of three final region/serv EU west/na team format 5 v5 tournament draft game set game type tournament draft map summon rift paus time allow 10 minut technic issu onli No show time 10 minut the player in the upper side of the bracket or left side of the match page will play blue side the team in the lower side of the bracket or right side of the match page will play red side core rule all match will be play use the tournament code that battlefi provid To get the code navig to the bracket and then click on the match that you re suppos to play then copi the code and past it into the leagu of legend game client by click play then select custom game then select the trophi icon player will have onli 10 minut to join the game room onc it ha been creat If your oppon doesn t show up or doesn t start the match in under these 10 minut pleas contact tournament admin in the discord channel If a player suffer a disconnect the player will be given 10 minut to reconnect to the game the team with the disconnect can request for a paus If they have not reconnect in that time the team will have to continu play without that player player are allow to stream their gameplay with at least a 3 minut delay at their own risk play for a chanc to win your share of $600 usd 1 st place team $300 2 nd place team $200 3 rd place team $100 cash prize will be paid out within 10 busi day via paypal edit for those that are part of differ server such a eun lan brazil asia server KR CN taiwan singapor zotac is also host a global tournament around the same time http /battlefi com/zotac cup fight for chariti sorri fam we didn t forget about you lt 3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing to see that function works\n",
    "porterStemming(lemmatize(df['Text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judging between the two types of root words, lemmatizing seems to be the better choice since porter stemming has cut down the word into gibberish as show im the example text above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizing all titles and texts in the dataframe\n",
    "df['Titles'] = df['Titles'].map(lambda x: lemmatize(x))\n",
    "df['Text'] = df['Text'].map(lambda x: lemmatize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Text</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ready to prove you re Challenger /r/LeagueofLe...</td>\n",
       "      <td>Hi Summoners Drum roll please we have somethin...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>106</td>\n",
       "      <td>3527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patch 9.7 Bug Megathread</td>\n",
       "      <td>Greetings Summoners With every new patch Riot ...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>24</td>\n",
       "      <td>3511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the ability to remove all client animation</td>\n",
       "      <td>Having to wait a duration longer than a Morgan...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>48</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know a champion is old when they still tal...</td>\n",
       "      <td>Udyr Cho gath and Mordekaiser are all pretty o...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbq Malice just locked in Tahm Kench jungle</td>\n",
       "      <td>In the bbq OLIVERS v APK PRINCE play off serie...</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>44</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles  \\\n",
       "0  Ready to prove you re Challenger /r/LeagueofLe...   \n",
       "1                           Patch 9.7 Bug Megathread   \n",
       "2     Add the ability to remove all client animation   \n",
       "3  You know a champion is old when they still tal...   \n",
       "4        bbq Malice just locked in Tahm Kench jungle   \n",
       "\n",
       "                                                Text        Subreddit  \\\n",
       "0  Hi Summoners Drum roll please we have somethin...  leagueoflegends   \n",
       "1  Greetings Summoners With every new patch Riot ...  leagueoflegends   \n",
       "2  Having to wait a duration longer than a Morgan...  leagueoflegends   \n",
       "3  Udyr Cho gath and Mordekaiser are all pretty o...  leagueoflegends   \n",
       "4  In the bbq OLIVERS v APK PRINCE play off serie...  leagueoflegends   \n",
       "\n",
       "   title_length  text_length  \n",
       "0           106         3527  \n",
       "1            24         3511  \n",
       "2            48          311  \n",
       "3            63           80  \n",
       "4            44          199  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see thta all punctuations have been removed correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Text</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>Subreddit_leagueoflegends</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ready to prove you re Challenger /r/LeagueofLe...</td>\n",
       "      <td>Hi Summoners Drum roll please we have somethin...</td>\n",
       "      <td>106</td>\n",
       "      <td>3527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Patch 9.7 Bug Megathread</td>\n",
       "      <td>Greetings Summoners With every new patch Riot ...</td>\n",
       "      <td>24</td>\n",
       "      <td>3511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add the ability to remove all client animation</td>\n",
       "      <td>Having to wait a duration longer than a Morgan...</td>\n",
       "      <td>48</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know a champion is old when they still tal...</td>\n",
       "      <td>Udyr Cho gath and Mordekaiser are all pretty o...</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bbq Malice just locked in Tahm Kench jungle</td>\n",
       "      <td>In the bbq OLIVERS v APK PRINCE play off serie...</td>\n",
       "      <td>44</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles  \\\n",
       "0  Ready to prove you re Challenger /r/LeagueofLe...   \n",
       "1                           Patch 9.7 Bug Megathread   \n",
       "2     Add the ability to remove all client animation   \n",
       "3  You know a champion is old when they still tal...   \n",
       "4        bbq Malice just locked in Tahm Kench jungle   \n",
       "\n",
       "                                                Text  title_length  \\\n",
       "0  Hi Summoners Drum roll please we have somethin...           106   \n",
       "1  Greetings Summoners With every new patch Riot ...            24   \n",
       "2  Having to wait a duration longer than a Morgan...            48   \n",
       "3  Udyr Cho gath and Mordekaiser are all pretty o...            63   \n",
       "4  In the bbq OLIVERS v APK PRINCE play off serie...            44   \n",
       "\n",
       "   text_length  Subreddit_leagueoflegends  \n",
       "0         3527                          1  \n",
       "1         3511                          1  \n",
       "2          311                          1  \n",
       "3           80                          1  \n",
       "4          199                          1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating dummy variables for the subreddit. Changing it so that it is a binary class\n",
    "df = pd.get_dummies(df, columns = ['Subreddit'], drop_first = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe of just league of legends posts\n",
    "mask = df['Subreddit_leagueoflegends'] == 1\n",
    "league_df = df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe of just dota2 posts\n",
    "mask = df['Subreddit_leagueoflegends'] == 0\n",
    "dota_df = df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and counting words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see the most used words in each individual data frame\n",
    "# Setting X and y values\n",
    "features = ['Text']\n",
    "X = league_df[features]\n",
    "y = league_df['Subreddit_leagueoflegends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiating train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using count vectorization as first model for text only\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "cv.fit(X_train['Text'])\n",
    "X_train_cv_text = cv.transform(X_train['Text'])\n",
    "X_test_cv_text = cv.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_cv_text.todense(), columns=cv.get_feature_names(),index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uh             6558\n",
       "http            351\n",
       "game            268\n",
       "com             210\n",
       "wa              209\n",
       "team            205\n",
       "just            202\n",
       "like            175\n",
       "skin            159\n",
       "amp             154\n",
       "mt              149\n",
       "champion        140\n",
       "play            140\n",
       "time            134\n",
       "x200b           122\n",
       "ha              121\n",
       "www             100\n",
       "know             87\n",
       "match            87\n",
       "damage           85\n",
       "player           83\n",
       "really           82\n",
       "change           82\n",
       "think            81\n",
       "10               81\n",
       "league           78\n",
       "new              76\n",
       "twitch           75\n",
       "make             75\n",
       "people           75\n",
       "               ... \n",
       "maining           1\n",
       "masquerade        1\n",
       "massiv            1\n",
       "massively         1\n",
       "media             1\n",
       "mentally          1\n",
       "members           1\n",
       "melon             1\n",
       "mejai             1\n",
       "meh               1\n",
       "meeting           1\n",
       "medium            1\n",
       "meditation        1\n",
       "mediocre          1\n",
       "medication        1\n",
       "medic             1\n",
       "meddle            1\n",
       "masterwork        1\n",
       "med               1\n",
       "mechanized        1\n",
       "mechanism         1\n",
       "measuring         1\n",
       "meal              1\n",
       "mdhqmyy           1\n",
       "maxing            1\n",
       "mature            1\n",
       "matthews          1\n",
       "matchmaking       1\n",
       "mastery           1\n",
       "lab               1\n",
       "Length: 5527, dtype: int64"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see the most used words in each individual data frame\n",
    "# Setting X and y values\n",
    "features = ['Text']\n",
    "X = dota_df[features]\n",
    "y = dota_df['Subreddit_leagueoflegends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiating train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using count vectorization as first model for text only\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "cv.fit(X_train['Text'])\n",
    "X_train_cv_text = cv.transform(X_train['Text'])\n",
    "X_test_cv_text = cv.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train_cv_text.todense(), columns=cv.get_feature_names(),index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http             619\n",
       "com              429\n",
       "amp              308\n",
       "game             242\n",
       "dota             198\n",
       "www              195\n",
       "team             181\n",
       "logo             177\n",
       "twitter          151\n",
       "00               149\n",
       "x200b            143\n",
       "like             131\n",
       "just             121\n",
       "wa               114\n",
       "player           112\n",
       "time             104\n",
       "hero              93\n",
       "30                85\n",
       "play              83\n",
       "pawn              81\n",
       "match             78\n",
       "twitch            76\n",
       "people            72\n",
       "tv                69\n",
       "gt                69\n",
       "point             68\n",
       "gaming            68\n",
       "ha                66\n",
       "weibo             66\n",
       "enemy             66\n",
       "                ... \n",
       "lbf                1\n",
       "lazy               1\n",
       "lay                1\n",
       "launched           1\n",
       "lifetime           1\n",
       "liked              1\n",
       "loading            1\n",
       "lil                1\n",
       "load               1\n",
       "lkkr921v04q21      1\n",
       "livid              1\n",
       "livestreams        1\n",
       "livestream         1\n",
       "lived              1\n",
       "literal            1\n",
       "listening          1\n",
       "listen             1\n",
       "liquidpedia        1\n",
       "liquidino          1\n",
       "liquid             1\n",
       "lip                1\n",
       "lion               1\n",
       "linken             1\n",
       "lini               1\n",
       "linger             1\n",
       "lined              1\n",
       "limmpdota          1\n",
       "limitation         1\n",
       "limb               1\n",
       "invis              1\n",
       "Length: 4825, dtype: int64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and y values for merged dataframe\n",
    "features = ['Titles', 'Text']\n",
    "X = df[features]\n",
    "y = df['Subreddit_leagueoflegends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiating train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using count vectorization as first model for text only\n",
    "cv = CountVectorizer(stop_words = 'english')\n",
    "cv.fit(X_train['Text'])\n",
    "X_train_cv_text = cv.transform(X_train['Text'])\n",
    "X_test_cv_text = cv.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting X_train_cv into a dataframe for data manipulation\n",
    "X_train_df = pd.DataFrame(X_train_cv_text.todense(), columns=cv.get_feature_names(),index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uh      6558\n",
       "http     896\n",
       "com      578\n",
       "game     504\n",
       "amp      442\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.sum().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of custom stop words\n",
    "custom_words = ['uh', 'http', 'com','game']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding custom stop words to english stop words\n",
    "custom_stop_words = stopwords.words('english')\n",
    "custom_stop_words.extend(custom_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words = custom_stop_words, min_df = 0.15)\n",
    "cv.fit(X_train['Text'])\n",
    "X_train_cv_text = cv.transform(X_train['Text'])\n",
    "X_test_cv_text = cv.transform(X_test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_text = pd.DataFrame(X_train_cv_text.todense(), columns=cv.get_feature_names(),index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df_text = pd.DataFrame(X_test_cv_text.todense(), columns=cv.get_feature_names(),index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amp      442\n",
       "team     370\n",
       "wa       351\n",
       "like     319\n",
       "get      268\n",
       "time     242\n",
       "x200b    240\n",
       "play     234\n",
       "would    207\n",
       "one      204\n",
       "know     168\n",
       "dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df_text.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of top words in the text\n",
    "top_text =pd.DataFrame({'word':X_train_df_text.columns,\n",
    "                           'word_count':X_train_df_text.sum()})\n",
    "top_text = top_text.sort_values('word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>know</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>would</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>one</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>play</th>\n",
       "      <td>play</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>time</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>get</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x200b</th>\n",
       "      <td>x200b</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>like</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>team</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>wa</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amp</th>\n",
       "      <td>amp</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  word_count\n",
       "know    know         159\n",
       "would  would         203\n",
       "one      one         211\n",
       "play    play         249\n",
       "time    time         262\n",
       "get      get         267\n",
       "x200b  x200b         270\n",
       "like    like         311\n",
       "team    team         351\n",
       "wa        wa         354\n",
       "amp      amp         449"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using count vectorization as first model for titles only\n",
    "cv = CountVectorizer(stop_words = 'english', min_df = 0.0245)\n",
    "cv.fit(X_train['Titles'])\n",
    "X_train_cv_title = cv.transform(X_train['Titles'])\n",
    "X_test_cv_title = cv.transform(X_test['Titles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_title = pd.DataFrame(X_train_cv_title.todense(), columns=cv.get_feature_names(),index = X_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df_title = pd.DataFrame(X_test_cv_title.todense(), columns=cv.get_feature_names(),index = X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "game        62\n",
       "dota        50\n",
       "new         37\n",
       "team        34\n",
       "champion    34\n",
       "skin        30\n",
       "league      28\n",
       "match       25\n",
       "player      23\n",
       "just        23\n",
       "2019        22\n",
       "help        21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df_title.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe of top words in the text\n",
    "top_title =pd.DataFrame({'word':X_train_df_title.columns,\n",
    "                           'word_count':X_train_df_title.sum()})\n",
    "top_title = top_title.sort_values('word_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>help</th>\n",
       "      <td>help</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>just</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player</th>\n",
       "      <td>player</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>match</th>\n",
       "      <td>match</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>league</th>\n",
       "      <td>league</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skin</th>\n",
       "      <td>skin</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>champion</th>\n",
       "      <td>champion</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>team</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>new</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dota</th>\n",
       "      <td>dota</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>game</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word  word_count\n",
       "help          help          21\n",
       "2019          2019          22\n",
       "just          just          23\n",
       "player      player          23\n",
       "match        match          25\n",
       "league      league          28\n",
       "skin          skin          30\n",
       "champion  champion          34\n",
       "team          team          34\n",
       "new            new          37\n",
       "dota          dota          50\n",
       "game          game          62"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Top Words in Title of Post')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating bar graph showing words and their count\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "ax1= fig.add_subplot(1,2,2)\n",
    "ax1.barh(top_text.index,top_text['word_count'],edgecolor='k');\n",
    "ax1.set_title(\"Top Words in Body of Post\")\n",
    "\n",
    "ax1= fig.add_subplot(1,2,1)\n",
    "ax1.barh(top_title.index,top_title['word_count'],edgecolor='k');\n",
    "ax1.set_title(\"Top Words in Title of Post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting X and y values\n",
    "# Setting X and y values for merged dataframe\n",
    "X = df['Text']\n",
    "y = df['Subreddit_leagueoflegends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(789,)\n",
      "(264,)\n",
      "(789,)\n",
      "(264,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done 648 out of 648 | elapsed: 36.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'lr__penalty': ['l1', 'l2'], 'cvec__max_features': [300, 500, 1000], 'cvec__min_df': [0.01, 0.05], 'cvec__max_df': [0.7, 0.8, 0.9], 'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'cvec__stop_words': ['english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"..., \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'uh', 'http', 'com', 'game']]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline for count vectorization for logistic regression\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params = {\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'cvec__max_features': [300, 500, 1000],\n",
    "    'cvec__min_df': [0.01,0.05],\n",
    "    'cvec__max_df': [0.7,0.8,0.9],\n",
    "    'cvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'cvec__stop_words': ['english', custom_stop_words]\n",
    "}\n",
    "\n",
    "gs_1 = GridSearchCV(pipe, param_grid = pipe_params, cv = 3, verbose = 1)\n",
    "gs_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.8, max_features=500, min_df=0.01,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "      ...penalty='l1', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False))])\n",
      "Train score:  0.9416983523447402\n",
      "Test score:  0.8257575757575758\n"
     ]
    }
   ],
   "source": [
    "# Finding best parameters as well as printing actual scores\n",
    "best_gs = gs_1.best_estimator_\n",
    "best_gs.fit(X_train,y_train)\n",
    "y_train_preds = best_gs.predict(X_train)\n",
    "y_test_preds = best_gs.predict(X_test)\n",
    "print(best_gs)\n",
    "print('Train score: ', accuracy_score(y_train, y_train_preds))\n",
    "print('Test score: ', accuracy_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 192 candidates, totalling 576 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  88 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=2)]: Done 388 tasks      | elapsed:   36.2s\n",
      "[Parallel(n_jobs=2)]: Done 576 out of 576 | elapsed:   54.1s finished\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'lr__penalty': ['l1', 'l2'], 'tfidf__max_features': [100, 300, 500, 1000], 'tfidf__min_df': [0.01, 0.05], 'tfidf__max_df': [0.8, 0.9], 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], 'tfidf__stop_words': ['english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"yo..., \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'uh', 'http', 'com', 'game']]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline and gridsearch for logistic regression\n",
    "pipe_tfidf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_params_tfidf = {\n",
    "    'lr__penalty': ['l1','l2'],\n",
    "    'tfidf__max_features': [100, 300, 500 , 1000],\n",
    "    'tfidf__min_df': [0.01,0.05],\n",
    "    'tfidf__max_df': [0.8,0.9],\n",
    "    'tfidf__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'tfidf__stop_words': ['english', custom_stop_words]\n",
    "}\n",
    "\n",
    "gs_2 = GridSearchCV(pipe_tfidf, param_grid = pipe_params_tfidf, cv = 3, verbose = 1, n_jobs = 2)\n",
    "gs_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9416983523447402\n",
      "Test score:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# creating pipeline for tfidf and logistic regression\n",
    "best_gs_tfidf = gs_2.best_estimator_\n",
    "best_gs_tfidf.fit(X_train,y_train)\n",
    "y_test_preds = best_gs_tfidf.predict(X_test)\n",
    "print('Train score: ', accuracy_score(y_train, y_train_preds))\n",
    "print('Test score: ', accuracy_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=2)]: Done 216 out of 216 | elapsed:   23.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('cvec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'cvec__max_features': [300, 500, 1000], 'cvec__min_df': [0.01, 0.05], 'cvec__max_df': [0.8, 0.9], 'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)], 'cvec__stop_words': ['english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'yo..., \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'uh', 'http', 'com', 'game']]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline for count vectorizor and MNB\n",
    "pipe_mnb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_mnb = {\n",
    "    'cvec__max_features': [300, 500, 1000],\n",
    "    'cvec__min_df': [0.01,0.05],\n",
    "    'cvec__max_df': [0.8,0.9],\n",
    "    'cvec__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'cvec__stop_words': ['english', custom_stop_words]\n",
    "}\n",
    "\n",
    "gs_3 = GridSearchCV(pipe_mnb, param_grid = pipe_params_mnb, cv = 3, verbose = 1, n_jobs = 2)\n",
    "gs_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9416983523447402\n",
      "Test score:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "best_gs_mnb = gs_3.best_estimator_\n",
    "best_gs_mnb.fit(X_train,y_train)\n",
    "y_test_preds = best_gs_tfidf.predict(X_test)\n",
    "print('Train score: ', accuracy_score(y_train, y_train_preds))\n",
    "print('Test score: ', accuracy_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=2)]: Done 216 out of 216 | elapsed:   23.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('mnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'tfidf__max_features': [300, 500, 1000], 'tfidf__min_df': [0.01, 0.05], 'tfidf__max_df': [0.8, 0.9], 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)], 'tfidf__stop_words': ['english', ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\"..., \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'uh', 'http', 'com', 'game']]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline for count vectorizor and MNB\n",
    "pipe_mnb_tfidf = Pipeline([\n",
    "    ('tfidf', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe_params_mnb_tfidf = {\n",
    "    'tfidf__max_features': [300, 500, 1000],\n",
    "    'tfidf__min_df': [0.01,0.05],\n",
    "    'tfidf__max_df': [0.8,0.9],\n",
    "    'tfidf__ngram_range': [(1,1),(1,2),(1,3)],\n",
    "    'tfidf__stop_words': ['english', custom_stop_words]\n",
    "}\n",
    "\n",
    "gs_4 = GridSearchCV(pipe_mnb_tfidf, param_grid = pipe_params_mnb_tfidf, cv = 3, verbose = 1, n_jobs = 2)\n",
    "gs_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9416983523447402\n",
      "Test score:  0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "best_gs_mnb = gs_4.best_estimator_\n",
    "best_gs_mnb.fit(X_train,y_train)\n",
    "y_test_preds = best_gs_tfidf.predict(X_test)\n",
    "print('Train score: ', accuracy_score(y_train, y_train_preds))\n",
    "print('Test score: ', accuracy_score(y_test, y_test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
